{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Describing data**\n",
    "\n",
    "For the last homework we discussed some simple commands for working with data frames using the FBI's UCR. With this homework, we'll get a bit more elaborate, venturing into exploratory analysis -- pulling stories from data. The practice involves repeated \"looks\" at a data set. A \"look\" might be some graphical representation of the data like a plot, or the output of some form of computation like a numerical summary, a table, or a \"model\" fit. We'll see all of them in this homework, under the heading of \"description.\" \n",
    "\n",
    "Statistians are exceptionally visual people, obsessed with \"seeing\" what the data have to offer, and \"views\" maybe provided through a variety of computational means. Our first descriptions will be graphical. As a journalist, you might think of this attempt to \"see\" as a kind of interview process, with each subsequent look, a follow-up question. R is, by design, expressive in statistical computations and graphics, meaning it allows us to formulate and act on statistical ideas in an easy way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Behavioral Risk Surveillance Survey**\n",
    "\n",
    "In the PDF file with this lesson, we introduced the BRFSS, a regular survey conducted by the CDC. Rather than give you the whole thing, we created a subset of variables to work with. Let's go over them and use them to examine some simple plotting devices. I've put it on github in R's own data format. (The reason for this is that some of the variables in the data set are categorical and we want an \"order\" to the categories -- like poor < good < very good < excellent.)\n",
    "\n",
    "You can either download the file from github or `source()` it directly from the site. Here we use `source()` because the data are in R's own format, as opposed to `read.csv()` which we used when the data consisted of a CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source(\"https://github.com/cocteau/lede2018/blob/master/data/cdc.R?raw=true\")\n",
    "head(cdc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables could be looked up in the codebook that comes along with the CDC data. For simplicity, we give them here.\n",
    "<br><br>\n",
    "`genhlth` - The respondent's general health\n",
    "<br> `physhlth` - For how many days during the past 30 days was the respondent's physical health not good?\n",
    "<br> `exerany` - Has the respondent exercised in the last 30 days? (1 = yes, 0 = no)\n",
    "<br> `hlthplan` - Does the respondent have a healthplan? (1 = yes, 0 = no)\n",
    "<br> `smoke100` - Has the respondent smoked at least 100 cigarettes in their lifetime? (1 = yes, 0 = no)\n",
    "<br> `height` - Respondent's height (inches)\n",
    "<br> `weight` - Respondent's weight (pounds)\n",
    "<br> `wtdesire` - The respondent's desired weight (pounds)\n",
    "<br> `age` - The respondent's age (years)\n",
    "<br> `gender` - The respondent's sex\n",
    "\n",
    "We can classify variables like the ones above into two kinds -- qualitative (categorical) or quantitative. \n",
    "\n",
    ">**Qualitative variables** “arise when individuals may fall into separate” categories which may not have a numerical relationship (a person's name or gender, for example) -- Qualitative data may be ordinal in the sense that there is a natural order to the categories. In the data above, `genhlth` is ordinal.\n",
    "<br><br>\n",
    "**Quantitative variables**, on the other hand, are numerical, “arising from counts or measurements” -- These data can, in turn, be loosely described as being continuous (able to take any number) or discrete (integers, say, or numerical values with just a small number of unique entries)\n",
    "\n",
    "For each of the variables in the `cdc` data frame, indicate whether it is qualitative or quantitative. Keep in mind that some responses might be coded as numeric values, but represent a qualitative variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put your answer here**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dplyr, take two.** The syntax so far is pretty simple. We have a data frame, R's answer to a simple table of data, and for the most part we have been using dollar signs to extract data from the table. And we will soon see simple functions that can summarize or do other things to the data. \n",
    "\n",
    "Much of statistics has to do with simple manipulations on tables. It's so important, in fact, that people have contributed tools that make these operations easy. We've introduced the dpyr package last time, but didn't really use it much. We will now.\n",
    "\n",
    "As we said before, you can think of R as being driven by \"verbs\". We have seen read.csv() and summary() and hist(), for example. We'll now make more extensive use of dplyr. It introduces a new set of verbs which, in each case, **takes a table (a data frame) as input and returns another, altered data frame as output.** These functions let you specify subsets, sort on columns, and create new columns. But in each case, you give a table and you get a table.\n",
    "\n",
    "- filter()\n",
    "- arrange()\n",
    "- select()\n",
    "- distinct()\n",
    "- mutate()\n",
    "- summarise()\n",
    "- group_by()\n",
    "- sample_n()\n",
    "\n",
    "The dplyr command glimpse() is a nice way to decide if your data are qualitative or quantitative. R's implementation of a qualitative variable is known as a \"factor\" and is denoted `fct` in the display below. An qualitative variable with ordered categories is denoted by `ord`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glimpse(cdc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frequency displays for qualitative data.** For qualitative or categorical data, the most obvious summary is a simple tabulation or count of the categories. The command table() can return this for you. From there, you have a variety of \"frequency displays\" that help make the comparison of counts more legible. We'll show a barplot and its cousin the mosaicplot.\n",
    "\n",
    "Remember that you \"extract\" a column of data from a data table (data frame) with the dollar sign, or you can use the dplyr verb `select()`. You can then pass it to some kind of summary function -- in this case table() to count cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(select(cdc,gender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(select(cdc,gender))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A barplot summarizes these counts with, well, bars. Each bar is associated with one of the counts in the table above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=8, repr.plot.height=6)\n",
    "\n",
    "barplot(table(select(cdc,gender)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a barplot of another qualitative variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen, we can tabulate any number of variables. Here we cross a respondent's general health and whether they've exercised recently. What do you think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(select(cdc,genhlth,exerany))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be hard to read a table like this, and so we appeal to a graphical display. The cousin of the barplot is the so-called mosaic plot. Let's make one and then describe what it means. (The first command below creates a square plot 6 by 6.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=6, repr.plot.height=6)\n",
    "\n",
    "mosaicplot(table(select(cdc,genhlth,exerany)),main=\"General health and exercise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot is constructed as follows. The width of each bar is set in proportion to the counts of `genhlth`. And so..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(select(cdc,genhlth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `poor` column is the thinnest and `very good` is widest, because these two categories have the least and most counts, respectively. The `fair` column is a bit less than half the width of the `excellent` column, and so on.\n",
    "\n",
    "Having set the width, we then set the heights of the boxes according to the proportion of people in each health category who have or have not exercised. And so..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(select(cdc,genhlth,exerany))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `poor` column, we have more people who have not exercised (category 0) than who have (category 1). This 0 box is taller than the 1 box for this column. As we move from `fair` to `excellent`, the proportion of respondents in each category who have exercised increases and so the box associated with category 0 shrinks, while the box for category 1 grows. \n",
    "\n",
    "**In the end, the area of each rectangle is proportional to the counts of the cells in the corresponding table.** The count for the cell corresponding to people in poor health who have exercised is the smallest, and the corresponding rectangle in the plot is the smallest. \n",
    "\n",
    "Got it?\n",
    "\n",
    "We can get a little fancier with some color. We can also provide some labels that make the chart more legible. What does it show?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaicplot(table(select(cdc,genhlth,exerany)),col=c(\"lightblue\",\"darkblue\"),main=\"General health and exercise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you think about it, there are actually two mosaic plots to be made with these two variables. We can also look a the \"transpose\" to see a different kind of relationship. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(select(cdc,exerany,genhlth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaicplot(table(select(cdc,exerany,genhlth)),main=\"Exercise and general health\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this new table, we first make the columns proportional to the number of people who have or have not exercised in the last 30 days. And so..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(select(cdc,exerany))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1 column is about three times as wide as the 0. Then within these two columns, we size the boxes according to the counts of the different overall health responses. What is the story here?\n",
    "\n",
    "To make this a bit nicer, we can use colors that come from a range. The Color Brewer package in R that is meant to take some of the guesswork out of choosing colors for displays like these or, its primary use, for mapping. You can choose colors depending on the kind of data you are representing (qualitative or quantitative) as well as its intended end-use or even its audience. The color \"palettes\" were designed by Prof. Cynthia Brewer, a geographer at Penn State and you can [see them here.](http://colorbrewer2.org/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"RColorBrewer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once installed, let's use it. We can generate all the color \"palettes\" that it knows about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=9, repr.plot.height=9)\n",
    "\n",
    "library(RColorBrewer)\n",
    "display.brewer.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see sequential palettes at the top that go from light to dark. These are good for qualitative variables. Why? Then we have divergent palettes that are good for categorical variables because they are as different as they can be. And then you have palettes that go from one color, through white, into another color. These are good if you have negative and positive values, say, and take white for zero.\n",
    "\n",
    "In our case we need five colors because there are five levels of `genhlth`. Let's use `Greens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pal <- brewer.pal(5,\"Greens\")\n",
    "pal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strings above represent the RGB values of the green colors in hexadecimal form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=6, repr.plot.height=6)\n",
    "\n",
    "mosaicplot(table(select(cdc,exerany,genhlth)),col=pal,main=\"Exercise and general health\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a mosaic plot of two other variables. Try adding color. What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpret the plot here**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frequency displays for quantitative variables.** With quantitative data we will want to see the \"shape\" of the distribution. We do this for several reasons. First, if there are multiple \"modes\" (bumps or clusters), you might want to figure out why. Multiple bumps means there are groups of data points that are more similar to each other than to the rest of the data set. These might suggest groups of respondents. \n",
    "\n",
    "The easiest frequency display is just a \"histogram\". In this case, we divide the range from the minimum to the maximum value of the variable into equally space \"bins\" and then count how many points we have in each bin. These counts are represented by the heights of bars in the plot. \n",
    "\n",
    "Here we look at the heights of women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "women <- filter(cdc,gender==\"f\")\n",
    "dim(women)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get there, remember that `select()` takes in a data frame and gives a data frame. The default version of `hist()` wants a vector of data instead. To extract a vector of data like we would get with the dollar sign, we can use the dplyr verb `pull()` -- it is an exception to the pattern of dplyr commands taking data frames and returning data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=8, repr.plot.height=6)\n",
    "\n",
    "hist(pull(women,height),breaks=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In words, this distribution has a symmetric shape. It has a single mode or \"bump.\" If you look closely at the heights you see something interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(pull(women,height),breaks=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People report their height in integers (counting numbers), as opposed to saying they are 70.33 inches tall. \n",
    "\n",
    "Make a data set for men and create a histogram of their weights. What do you see? Zoom in with a large number of breaks and tell me what you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tell me what you see**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When variables are skewed rather than symmetric (meaning one half is more spread out than the other -- the weight histogram above is a good example), then summary statistics like the mean are problematic. We will see that the mean can be heavily influenced by a single, large value and so skewed data can cause the mean to be a bad summary statistic. The mean and standard deviation (we'll define these formally in class) are associated with the bell curve or normal distribution -- it is the canonical \"well behaved\" symmetric shape. For skewed data, we might use something more \"robust\" like a median. We'll get to this in detail in class.\n",
    "\n",
    "Determining if something is bell shaped is important, so much so that there are better plots for making the judgement call. In class we'll see something called a Q-Q plot (quantile-quantile) that, if a straight line, means the data are closely approximated by a bell curve. Here's one of men's weights just to show you what it looks like. We'll go over the construction in class. For now, the point is that a graphic that has us decide if our plot follows a line or not is easier to work with than judging shape from a histogram.\n",
    "\n",
    "The plot below of men's weights starts like a line and then tips up. That tip up means the right end of the data are more spread out than you'd expect if the data were a bell shape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=6, repr.plot.height=6)\n",
    "\n",
    "men <- filter(cdc,gender==\"m\")\n",
    "qqnorm(pull(men,weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The hardest places to live**\n",
    "\n",
    "The next data set comes from the New York Times as part of a series on life in the United States. [Skim the article here.](https://www.nytimes.com/2014/06/26/upshot/where-are-the-hardest-places-to-live-in-the-us.html) There's a lot to quibble with in this piece, but let's just yank the data and have a look at some of the variables. For a bonus, find where the data are hiding! I have pulled it for you and put it on the github site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard <- read.csv(\"https://github.com/cocteau/lede2018/raw/master/data/unemployment.csv\",as.is=TRUE)\n",
    "head(hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row is a county in the US and the variables are described in the NYT article. Let's sort the data by life expectancy, putting the counties with people having the shortest life expectancies first. This uses the dplyr verb `arrange()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(arrange(hard,life))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glimpse(hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a histogram of a couple of the varialbles and describe their shapes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we want to consider the relationship between two or more variables. To see the \"shape\" of that relationship, we might instead create a \"scatter plot\" -- we'll get a lot of mileage out of this display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(income~education,data=hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To maybe get a little fancy, we can add a \"best fit\" or \"least squares\" or \"regression\" line to this plot. It is meant to describe a simple linear relationship between two variables (in this case). The line highlights aspects of the relationship between the two variables and might be used here as a visual device for judging the adequacy of such a simple description. \n",
    "\n",
    "We also include it because it shows you how easy it is to work with data in R. Oh and lm() stands for \"linear model.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit <- lm(income~education,data=hard)\n",
    "plot(income~education,data=hard)\n",
    "abline(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try some others\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a sense of more than two variables, we might look at several scatterplots at once. We can do this with the \"pairs\" command. Explain what this is doing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs(select(hard,education, income, unemployment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus on comparing a few states. These are a little random, but Kentucky is featured in the Times' story. You can mix it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states <- c(\"Georgia\",\"Kansas\",\"Kentucky\",\"Missouri\",\"Texas\",\"Virginia\")\n",
    "hard2 <- filter(hard,state %in% states)\n",
    "head(hard2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditioning is a way to introduce categorical or qualitative data into your analysis. Not dissimilar from mosaic plots, we can create separate displays for different categories. Here we divide the relationship between income and education \"given\" state. \n",
    "\n",
    "We are going to use a built-in package called `lattice`. It allows for simple conditioning. The downside is that it uses new verbs and not just the standard `plot()`. Here is a plot of income as a function of education given state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(lattice)\n",
    "xyplot(income~education|state,data=hard2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that all the axes are the same and so we can directly compare the states easily. Lattice also has some simple facilities for 3d plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud(life~disability+obesity,data=hard2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud(life~disability+obesity|state,data=hard2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is a gender comparison from the CDC data set. The `lattice` command `histogram()` is its own version that allows for conditioning. Here we make two histograms of respondent heights to the CDC data set, broken down by gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(~height|gender,data=cdc,layout=c(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A/B Testing**\n",
    "\n",
    "The mechanism behind randomized trials is underneath a host of processes that are optimizing headlines, moving content around on home pages, and testing out what kind of content is pushed out to social media. [Have a read about what Buzzfeed does.](https://ijnet.org/en/blog/adaptation-ab-testing-and-analytics-how-buzzfeed-optimizes-news-its-audience) We are now going to load up the data given to us by the New York Times. [Pull it from Dropbox](https://www.dropbox.com/s/x8ud9taqg12s7c4/nyt.csv?dl=0) and place it in the same folder as your notebook. It's a little old now, but the principles are the same. (It was too big for github.)\n",
    "\n",
    "The treatment, you will recall, was replacing a Tab layout versus a List layout for the top cities and most e-mailed stories. Again, this was an old version of the site. The treatment is stored in a variable called \"Variation\" (which page variation were people shown) and \"IfClicked\" (did they click or not). Read in the data and then have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt <- read.csv(\"nyt.csv\")\n",
    "head(nyt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables above include the following.\n",
    "\n",
    "> User_ID - A unique number for each visitor\n",
    "<br> UserVisit_ID - A unique number for each visit\n",
    "<br> StartTime_SSE - UNIX time for the start of the visit\n",
    "<br> StartTime_English - A more humanly readable version of the time\n",
    "<br> VisitLength - The number of seconds the visitor was reading the Travel Section pages\n",
    "<br> Variation - The version of the page they received\n",
    "<br> RefererURL - The page they clicked on to get to the Travel Section (if any)\n",
    "<br> EntryPageUrl - The first page on nytimes.com they visited\n",
    "<br> Pageviews - The number of pages viewed in the Travel Section\n",
    "<br> TotalVisits - The total number of visits to the site\n",
    "<br> TimeSinceFirstVisit (days) - How long had it been since their first visit\n",
    "<br> UserAgent - Their browser\n",
    "<br> TotalClicks - How many times did they ckick on the \"most popular\" field\n",
    "<br> IfClicked - 0/1 did they click on the \"most popular\" field at least once\n",
    "\n",
    "This data set was collected in 2008 (sadly) and even then you get an idea for how much information sites have to help adapt content to your preferences. A/B testing is just one strategy. There is plenty here to build up kind of profile of your viewing habits on the NYTimes site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(nyt$Variation,nyt$IfClicked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"0\" column counts people who did not click in the \"most popular\" area, while a \"1\" counts all those who did. We see the Tabs option had a lot more people clicking than the List option. But could this difference be due to the randomization?\n",
    "\n",
    "Following how we proceeded with Hill's data, we can make a copy of the data set and then shuffle the treatment column, under the null hypothesis that both Tabs and Lists encourage people to click on the \"most popular\" field equally. Let's have a look at a few simulated tables and get a sense of how likely, say, having 1200 people who saw Tabs click on the field. Is it rare, suggesting the null hypothesis is wrong; or is it consistent with the null distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newnyt <- nyt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do this a few times and watch the count of people in the \"died\"-\"penicillin\" cell\n",
    "\n",
    "newnyt$Variation <- sample(nyt$Variation)\n",
    "table(select(newnyt,Variation,IfClicked))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this data set is big (130k rows), we will only simulate 1000 times. The results are clear enough even with this smaller number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtrials <- rep(0,1000)\n",
    "\n",
    "for(i in 1:1000){\n",
    "    newnyt$Variation <- sample(nyt$Variation)\n",
    "    newtrials[i] <- sum(newnyt$Variation==\"Tabs\" & newnyt$IfClicked==1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(newtrials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think? Is the data we observed from the Tabs and List experiment consistent with the null hypothesis of \"no difference\" or is it not? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put your answer here**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
